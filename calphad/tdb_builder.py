#!/usr/bin/env python3
"""
TDB 构建与校验工具：提供 full_pipeline / extract_only / validate_only 三种模式，
用于复制/拼接 TDB 并可选使用 pycalphad 验证可加载性。
"""

from __future__ import annotations

import argparse
import json
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Sequence

# Categories mirror the prior agent workflow.
CATEGORIES = ("full_pipeline", "extract_only", "validate_only")
DEFAULT_OUTPUT = Path(__file__).resolve().parent / "thermo" / "Database" / "built_output.tdb"
DEFAULT_SKELETON = "! TDB skeleton generated by tdb_builder.py\n$ Fill in functions/parameters before use.\n"


@dataclass
class Artifact:
    kind: str
    path: str
    note: str


@dataclass
class WorkflowResult:
    category: str
    status: str
    output_text: str
    artifacts: list[Artifact]


def classify_message(message: str | None) -> str:
    """
    Lightweight text classifier to keep CLI compatibility with the original agent logic.
    Defaults to full_pipeline if no clear signal is present.
    """
    if not message:
        return "full_pipeline"
    text = message.lower()
    mentions_extract = any(token in text for token in ("extract", "提取"))
    mentions_validate = any(token in text for token in ("validate", "验证"))
    mentions_full = any(token in text for token in ("full", "全部", "全流程"))
    if mentions_full or (mentions_extract and mentions_validate):
        return "full_pipeline"
    if mentions_extract:
        return "extract_only"
    if mentions_validate:
        return "validate_only"
    return "full_pipeline"


def extract_tdb(source: Path | None, fragments: Sequence[Path], output: Path) -> Artifact:
    """
    Build a TDB file by copying a source, concatenating fragments, or emitting a skeleton.
    """
    if source and fragments:
        raise ValueError("Provide either a source TDB or fragments, not both.")

    output = output.resolve()
    output.parent.mkdir(parents=True, exist_ok=True)

    if fragments:
        contents = []
        for frag in fragments:
            frag_path = frag.resolve()
            if not frag_path.exists():
                raise FileNotFoundError(f"TDB fragment not found: {frag_path}")
            contents.append(frag_path.read_text(encoding="utf-8"))
        tdb_text = "\n".join(contents)
        note = f"Concatenated {len(fragments)} fragment(s)."
    elif source:
        source_path = source.resolve()
        if not source_path.exists():
            raise FileNotFoundError(f"Source TDB not found: {source_path}")
        tdb_text = source_path.read_text(encoding="utf-8")
        note = f"Copied from {source_path}"
    else:
        tdb_text = DEFAULT_SKELETON
        note = "Created empty TDB skeleton (fill in parameters before use)."

    output.write_text(tdb_text, encoding="utf-8")
    return Artifact(kind="tdb", path=str(output), note=note)


def validate_tdb(path: Path) -> tuple[bool, str]:
    """
    Try loading the TDB with pycalphad; report success/failure message.
    """
    target = path.resolve()
    if not target.exists():
        return False, f"TDB not found: {target}"
    try:
        from pycalphad import Database  # type: ignore
    except Exception as exc:  # pragma: no cover - optional dependency
        return False, f"pycalphad import failed: {exc}"
    try:
        Database(target)
    except Exception as exc:
        return False, f"pycalphad failed to load {target}: {exc}"
    return True, f"Validation succeeded for {target}"


def run_full_pipeline(
    source: Path | None, fragments: Sequence[Path], output: Path, skip_validation: bool
) -> WorkflowResult:
    artifacts: list[Artifact] = []
    try:
        artifact = extract_tdb(source, fragments, output)
        artifacts.append(artifact)
    except Exception as exc:
        return WorkflowResult(
            category="full_pipeline",
            status="error",
            output_text=f"Extraction failed: {exc}",
            artifacts=artifacts,
        )

    if skip_validation:
        return WorkflowResult(
            category="full_pipeline",
            status="ok",
            output_text="Extraction completed (validation skipped).",
            artifacts=artifacts,
        )

    ok, message = validate_tdb(Path(artifacts[-1].path))
    return WorkflowResult(
        category="full_pipeline",
        status="ok" if ok else "error",
        output_text=f"Extraction + validation result: {message}",
        artifacts=artifacts,
    )


def run_extract_only(source: Path | None, fragments: Sequence[Path], output: Path) -> WorkflowResult:
    artifacts: list[Artifact] = []
    try:
        artifact = extract_tdb(source, fragments, output)
        artifacts.append(artifact)
        return WorkflowResult(
            category="extract_only",
            status="ok",
            output_text=f"Extraction complete -> {artifact.path}",
            artifacts=artifacts,
        )
    except Exception as exc:
        return WorkflowResult(
            category="extract_only",
            status="error",
            output_text=f"Extraction failed: {exc}",
            artifacts=artifacts,
        )


def run_validate_only(target: Path) -> WorkflowResult:
    ok, message = validate_tdb(target)
    return WorkflowResult(
        category="validate_only",
        status="ok" if ok else "error",
        output_text=message,
        artifacts=[],
    )


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="TDB builder/validator with full_pipeline, extract_only, or validate_only modes."
    )
    parser.add_argument(
        "--mode",
        choices=CATEGORIES,
        help="Explicit mode; if omitted, auto-classify from --message (default full_pipeline).",
    )
    parser.add_argument(
        "--message",
        help="Free text to classify (mirrors original agent workflow); ignored when --mode is set.",
    )
    parser.add_argument(
        "--source",
        type=Path,
        help="Existing TDB to copy or validate.",
    )
    parser.add_argument(
        "--fragments",
        type=Path,
        nargs="*",
        default=[],
        help="One or more TDB fragment files to concatenate.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT,
        help=f"Output TDB path for extract/full (default: {DEFAULT_OUTPUT}).",
    )
    parser.add_argument(
        "--skip-validation",
        action="store_true",
        help="Skip validation step in full_pipeline mode.",
    )
    parser.add_argument(
        "--human",
        action="store_true",
        help="Print human-readable summary instead of JSON schema output.",
    )
    return parser.parse_args()


def main() -> None:
    args = parse_args()
    category = args.mode or classify_message(args.message)

    if category == "full_pipeline":
        result = run_full_pipeline(args.source, args.fragments, args.output, skip_validation=args.skip_validation)
    elif category == "extract_only":
        result = run_extract_only(args.source, args.fragments, args.output)
    else:
        target = args.source or args.output
        result = run_validate_only(target)

    if args.human:
        print(f"[{result.status.upper()}] ({result.category}) {result.output_text}")
        for art in result.artifacts:
            print(f"- {art.kind}: {art.path} ({art.note})")
    else:
        print(json.dumps(asdict(result), ensure_ascii=False, indent=2))

    if result.status != "ok":
        raise SystemExit(1)


if __name__ == "__main__":
    main()
